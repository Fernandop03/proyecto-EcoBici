# PrÃ¡ctica Spark: AnÃ¡lisis de Movilidad Urbana con EcoBici en CDM
**Universidad Nacional AutÃ³noma de MÃ©xico**

**Facultad de Estudios Superiores AcatlÃ¡n**

**Licenciatura en MatemÃ¡ticas Aplicadas y ComputaciÃ³n**

**ProgramaciÃ³n Paralela y Concurrente**

Prof. JosÃ© Gustavo Fuentes Cabrera

04/05/2025

**Alumno:** RamÃ­rez GÃ³mez Fernando Axel

**No. C.** 422066442

![image](https://github.com/user-attachments/assets/ec7c69d1-1d5a-4280-8eb0-5149a3cca6c0)


# DescripciÃ³n general

Este repositorio contiene el cÃ³digo y los resultados del proyecto de la PrÃ¡ctica 2 de la materia ProgramaciÃ³n Paralela y Concurrente, enfocada en el anÃ¡lisis de datos de movilidad urbana en la Ciudad de MÃ©xico utilizando Apache Spark.

![image](https://github.com/user-attachments/assets/78c17592-80a4-434e-8236-46233e0d2c5b)

## ğŸ¯ Objetivo

Aplicar los conceptos de programaciÃ³n distribuida con Apache Spark (RDDs, DataFrames, transformaciones y acciones) para extraer informaciÃ³n significativa de un dataset real, mejorando la eficiencia del anÃ¡lisis de datos a gran escala y facilitando la visualizaciÃ³n de patrones clave.

## ğŸ§  IntroducciÃ³n

El sistema EcoBici ofrece una oportunidad Ãºnica para estudiar el comportamiento de la movilidad urbana. En este proyecto se analiza un conjunto de datos con miles de registros de viajes, aplicando tÃ©cnicas de procesamiento distribuido con Spark y visualizaciÃ³n local con Pandas y Matplotlib.

## Dataset

El dataset utilizado consiste en registros individuales de viajes de EcoBici. Las columnas clave incluyen:

* `anio`: AÃ±o del viaje.
* `mes`: Mes del viaje.
* `fecha_referencia`: Fecha especÃ­fica del viaje.
* `bici`: Identificador Ãºnico de la bicicleta.
* `mins_viaje`: DuraciÃ³n del viaje en minutos.
* `hrs_viaje`: DuraciÃ³n del viaje en horas.
* `dias_viaje`: DuraciÃ³n del viaje en dÃ­as.
* `distancia_approx`: Distancia aproximada recorrida.

Los datos provienen del Portal de Datos Abiertos de la CDMX.

## MetodologÃ­a

El proyecto se dividiÃ³ en dos fases principales:

1.  **AnÃ¡lisis de Datos con PySpark (`ecobici_analysis.py`)**:
    * Carga y limpieza del dataset desde un archivo CSV (`viajes_individuales.csv`).
    * Transformaciones para extraer la hora del dÃ­a, dÃ­a de la semana e identificar fines de semana.
    * AnÃ¡lisis de patrones de uso mediante "rutas simuladas" basadas en duraciÃ³n y distancia.
    * AnÃ¡lisis de la demanda por rangos horarios.
    * AnÃ¡lisis de rendimiento y eficiencia de la flota de bicicletas.
    * Guardado de los resultados agregados en formato CSV.

2.  **VisualizaciÃ³n de Resultados con Pandas y Matplotlib/Seaborn (`ecobici_visualization.py`)**:
    * Carga de los resultados agregados desde los archivos CSV generados por Spark.
    * GeneraciÃ³n de grÃ¡ficos de barras para visualizar los principales hallazgos (tipos de viaje mÃ¡s frecuentes, demanda horaria, bicicletas mÃ¡s eficientes).
    * Guardado de las visualizaciones en formato PNG.


## ğŸ“ Estructura del Proyecto

```graphql
Eco_Bici/                                # Directorio raÃ­z del proyecto
â”‚
â”œâ”€â”€ Eco_Bici/                            # Carpeta principal con el cÃ³digo fuente
â”‚   â”œâ”€â”€ api.py                           # Funciones de conexiÃ³n o simulaciÃ³n de API de Ecobici
â”‚   â”œâ”€â”€ data-2025-04-18.csv              # Conjunto de datos principal para el anÃ¡lisis
â”‚   â”œâ”€â”€ ecobici_analysis.py              # MÃ³dulo de anÃ¡lisis estadÃ­stico y procesamiento de datos
â”‚   â”œâ”€â”€ ecobici_visualization.py         # MÃ³dulo para generar grÃ¡ficas y visualizaciones
â”‚   â”œâ”€â”€ resultados_bicis_mas_usadas.csv  # Resultados del anÃ¡lisis de uso por bicicleta
â”‚   â”œâ”€â”€ resultados_categorias_duracion.csv  # ClasificaciÃ³n por duraciÃ³n de los viajes
â”‚   â”œâ”€â”€ resultados_uso_diario.csv        # Uso agregado por dÃ­a
â”‚   â”œâ”€â”€ resultados_uso_mensual.csv       # Uso agregado por mes
â”‚   â”œâ”€â”€ testspark.py                     # Prueba de integraciÃ³n con PySpark
â”‚   â”œâ”€â”€ viajes_individuales.csv          # Detalle de viajes individuales para anÃ¡lisis granular
â”‚
â”‚   â”œâ”€â”€ resultados/                      # Resultados procesados automÃ¡ticamente (formato Spark)
â”‚   â”‚   â”œâ”€â”€ eficiencia.csv/              # Datos de eficiencia por bicicleta
â”‚   â”‚   â”œâ”€â”€ horas.csv/                   # Frecuencia de viajes por hora
â”‚   â”‚   â”œâ”€â”€ rutas.csv/                   # InformaciÃ³n sobre las rutas mÃ¡s frecuentes
â”‚
â”‚   â”œâ”€â”€ visualizaciones/                 # Visualizaciones generadas automÃ¡ticamente
â”‚   â”‚   â”œâ”€â”€ impacto_demanda_horaria.png
â”‚   â”‚   â”œâ”€â”€ impacto_eficiencia_bicis.png
â”‚   â”‚   â”œâ”€â”€ impacto_tipos_viaje.png
```

## âš™ï¸ Â¿CÃ³mo se ejecuta?

1.  Instala las dependencias necesarias:

    ```bash
    pip install -r requirements.txt
    ```

2.  Ejecuta el anÃ¡lisis con Spark:

    ```bash
    python ecobici_analysis.py
    ```

3.  Genera las visualizaciones:

    ```bash
    python ecobici_visualization.py
    ```

## ğŸ“Š MetodologÃ­a Aplicada

### ğŸ”¹ AnÃ¡lisis de Datos (Spark)
* Limpieza de datos desde `viajes_individuales.csv`.
* Transformaciones y generaciÃ³n de variables como hora, dÃ­a, tipo de viaje.
* Agregaciones por duraciÃ³n, eficiencia, demanda por hora y rendimiento de bicicletas.

### ğŸ”¹ VisualizaciÃ³n (Pandas + Matplotlib/Seaborn)
* Carga de resultados agregados.
* GeneraciÃ³n de grÃ¡ficos:
    * Demanda horaria.
    * Bicicletas mÃ¡s utilizadas.
    * Rutas mÃ¡s frecuentes.

## ğŸ“ˆ Principales Hallazgos

* **Patrones de uso:** Los viajes mÃ¡s comunes son breves y frecuentes en horarios laborales.
* **Demanda por hora:** La mayor actividad se registra entre las 8-9 am y 6-7 pm.
* **Rendimiento de flota:** Se identificaron bicicletas con alta y baja eficiencia para mantenimiento o sustituciÃ³n.

## ğŸ§  RelaciÃ³n con los Paradigmas de ProgramaciÃ³n

* **DistribuciÃ³n:** Apache Spark permite dividir el procesamiento del dataset en tareas paralelas.
* **TransformaciÃ³n Funcional:** Uso de operaciones inmutables en RDDs y DataFrames.
* **VisualizaciÃ³n Secuencial:** Herramientas como Pandas y Matplotlib se usan eficientemente en etapas posteriores del pipeline.

## AnÃ¡lisis de Resultados y Valor de Negocio

El anÃ¡lisis de los resultados proporciona informaciÃ³n valiosa para la gestiÃ³n del sistema EcoBici:

* **Patrones de Uso por Tipo de Viaje**: IdentificaciÃ³n de las combinaciones de duraciÃ³n y distancia mÃ¡s populares, ayudando a entender el comportamiento del usuario.
* **Demanda Horaria**: IdentificaciÃ³n de los perÃ­odos del dÃ­a con mayor y menor actividad, permitiendo optimizar la programaciÃ³n de rebalanceo, mantenimiento y personal.
* **Rendimiento de la Flota**: IdentificaciÃ³n de las bicicletas con mayor uso o eficiencia, Ãºtil para priorizar mantenimiento preventivo e investigar unidades con bajo rendimiento.

Estos insights permiten tomar decisiones informadas para optimizar la operaciÃ³n y mejorar la experiencia del usuario.


## âœ… ConclusiÃ³n

Este proyecto demostrÃ³ la eficacia de usar Apache Spark como motor de anÃ¡lisis distribuido para grandes volÃºmenes de datos reales. La combinaciÃ³n con herramientas de visualizaciÃ³n locales brinda una soluciÃ³n escalable, interpretativa y eficiente para resolver problemas urbanos.

## ğŸ¤– Uso Ã‰tico de Herramientas de IA

Durante el desarrollo del proyecto se utilizaron herramientas de IA (Gemini, ChatGPT) de forma Ã©tica y documentada para:

* Comprender conceptos de Spark.
* Optimizar cÃ³digo.
* Redactar documentaciÃ³n tÃ©cnica.

## ğŸ“š Referencias

* Agencia Digital de InnovaciÃ³n PÃºblica. (2023). Datos de bicicletas (Ecobici). Portal de Datos Abiertos CDMX.
* Google. (2025). Gemini [Modelo de lenguaje grande].

Se uso para:
- EstructuraciÃ³n y revisiÃ³n tÃ©cnica del cÃ³digo.
- Mejora de redacciÃ³n en la documentaciÃ³n.
- GeneraciÃ³n de ideas para el diseÃ±o del sistema.
